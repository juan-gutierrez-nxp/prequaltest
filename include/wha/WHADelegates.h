/*
 * Copyright 2017-2018 Amazon.com, Inc. or its affiliates.  All Rights Reserved.
 *
 * You may not use this file except in compliance with the terms and conditions
 * set forth in the Software Release Agreement or Pre-Release Software Agreement with Amazon
 * that governs use of this file.
 *
 * THESE MATERIALS ARE PROVIDED ON AN "AS IS" BASIS.  AMAZON SPECIFICALLY DISCLAIMS,
 * WITH RESPECT TO THESE MATERIALS, ALL WARRANTIES, EXPRESS, IMPLIED, OR STATUTORY,
 * INCLUDING THE IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR
 * PURPOSE, AND NON-INFRINGEMENT.
 */

#ifndef AMAZON_WHA_DELEGATES_H_
#define AMAZON_WHA_DELEGATES_H_

#include <stdint.h> // needed for int64_t
#include <stdio.h> // needed for size_t

#define WHA_PUBLIC __attribute__ ((visibility ("default")))
#define WHA_PRIVATE __attribute__ ((visibility ("hidden")))

namespace wha {

// Forward declare WHA for FocusDelegate
class WHA;

/**
 * Cloud delegate.
 *
 * This class supports WHALib to send Events up to the cloud
 * and forward Directives for related clients to take care of.
 */
class WHA_PUBLIC CloudDelegate {
public:
    virtual ~CloudDelegate() {};

    /**
     * Get the Alexa connection state.
     *
     * @return True if the client is currently connected to Alexa Service.
     */
    virtual bool hasAlexaConnection() = 0;

    /**
     * Send Events up to the cloud. This is called when WHA needs to send
     * Events to the cloud. The AVS client is responsible to use the provided
     * parameters to construct the whole message JSON and send it up to the cloud
     * with the correct endpoint path. Note that any missing elements such as
     * messageId should be generated by the client. This method should be nonblocking
     * and thread safe.
     *
     * @param nameSpace Message namespace.
     * @param name Message name.
     * @param payload Stringified payload JSON.
     * @param uri URI specifying custom endpoint. Use the default path
     *            "/{{API version}}/events" when it's empty. Otherwise,
     *            use "/{{API version}}/{uri}" to send up this Event.
     */
    virtual void sendEvent(const char* nameSpace, const char* name,
                           const char* payload, const char* uri) = 0;

    /**
     * Update ClusterSate context. ClusterState context is opaque to the AVS clients,
     * basically it contains the cluster playback state that can only be generared by
     * WHA. Just like any other context defined here:
     * https://developer.amazon.com/docs/alexa-voice-service/context.html. Therefore,
     * client is required to persist the ClusterSate context and send it up with other
     * contexts when needed. This method should be thread safe.
     *
     * @param context Stringified ClusterState JSON. If it is a nullptr, client should
     *                delete this context and remove it from context JSON. Basically,
     *                it means there isn't valid WHA related state anymore.
     */
    virtual void updateClusterStateContext(const char* context) = 0;

    /**
     * Forwad AVS Directive to the client who needs to take care of. This method should
     * be called when WHA decides to forward a Directive back to the client. Specifically,
     * there is a WHA Directive that has an enclosed Directive inside of the paylaod.
     * In this case, WHA would forward these Directives to the client when it cannot process
     * it. It must be AVS Directive and the client can process it. This method should be
     * nonblocking and thread safe. Client may need to copy the parameter and handle it
     * asynchronously.
     *
     * @param message A stringfied Diretive message JSON that can be used by an AVS client.
     */
    virtual void forwardAVSDirective(const char* message) = 0;
};

/**
 * Device informaion delegate.
 *
 * WHA will query all the following device specific information
 * at the initiate time or any related event like network change.
 */
class WHA_PUBLIC DeviceInfoDelegate {
public:
    virtual ~DeviceInfoDelegate() {};

    /**
     * Get the local device IP address.
     * @return The local device IPv4 address. Return nullptr if it is
     *         unspecified or unavailable.
     */
    virtual const char* getIPAddress() = 0;

    /**
     * Get the BSSID. The expected BSSID should be the raw value with
     * six groups of two hexadecimal digits in lower case separated by
     * colons, example: "28:c6:8e:0b:09:fa".
     *
     * @return The BSSID of the device connected to. Return nullptr if it
     *         is unspecified or unavailable.
     */
    virtual const char* getBSSID() = 0;

    /**
     * Get the ESSID. The expected SSID should be the raw value without being
     * obfuscated.
     *
     * @return The ESSID to which the device is currently associated. Return
     *         nullptr if it is unspecified or unavailable.
     */
    virtual const char* getESSID() = 0;

    /**
     * Get RSSI value.
     * @return The current RSSI value.
     */
    virtual float getRSSI() = 0;

    /**
     * Get device main volume in percentage (0 ~ 100).
     *
     * @return The current main volume rounded in whole integer.
     */
    virtual int getDeviceMainVolume() = 0;

    /**
     * Get the number of seconds that the device has been idle. In this case,
     * idle time is defined as time in seconds since a user has interacted with the device.
     *
     * @return The number of seconds since a user interaction has occurred on the device.
     */
    virtual int getDeviceIdleTime() = 0;

    /**
     * Get the local device Id. It should be unique and static like DSN. Note
     * that this value will be shared with other devices or related services,
     * vendors are responsible to obfuscate it for privacy if necessary.
     *
     * NOTE: We will remove this method when WHACS starts to generate the
     * device identifier.
     *
     * @return A unique and static device Id.
     */
    virtual const char* getDeviceId() = 0;

    /**
     * Get the Amazon ID. Amazon ID is the unique identifier for a certain type of device.
     * We can find it at https://developer.amazon.com/avs/home.html#/avs/welcome.
     * Each type of alexa engined device should be assigned an Amazon ID by Amazon.
     *
     * @return The local device's Amazon ID.
     */
    virtual const char* getAmazonId() = 0;

    /**
     * Tell if the device is under debug build or not. This is used for privacy
     * logging. Basically, if it is a release version, privacy information in the
     * will be obfuscated for privacy logging.
     *
     * @return True if it is debug build.
     */
    virtual bool isDebugBuild() = 0;

    /**
     * Get the registration state of the local device.
     *
     * @return True if the device is currently registered with an valid Alexa account.
     */
    virtual bool getRegistrationState() = 0;

    /**
     * Tell if the system clock is accurate or not. At initialization time when WHA service
     * is started by 'WHA::run()', WHA needs an system clock that is accurate to the minute
     * to generate certificates for inter-device communication. This method is used to address
     * the case in which the system clock is not accurate at device boot up time.
     *
     * This call should be blocked until the system has heard back from a time server and
     * updated the system clock or if two minutes have passed without an accurate clock.
     *
     * @return True if device has an accurate system clock within two minutes since this
     *              method get called, otherwise, return false.
     */
    virtual bool waitForAccurateSystemClock() = 0;
};

/**
 * Supported PCM formats
 * @see PlaybackDelegate::start()
 */
enum AudioFormat {
    /** Signed 16-bit integer, interleaved */
    AUDIO_FORMAT_PCM_S16
};

/**
 * PlaybackDelegate::stop() behavior
 */
enum StopBehavior {
    /** Drain (play) all the samples and then stop */
    STOP_DRAIN,
    /** Drop all the samples and stop */
    STOP_DROP
};

/**
 * Playback delegate.
 *
 * Audio Player will call start() at the beginning of stream,
 * then write() in a loop and stop() at the end of stream.
 * pause(), flush(), resume() is called when playback is paused/resumed
 * by cloud or by the device itself.
 *
 * Player pushes as much data as possible to keep the audio
 * pipeline full. If no data available, player will call underrun().
 * It is recommended to not buffer large amounts of data as it will
 * cause delays on resume because player does not resend
 * already sent data.
 *
 * @note All the functions are called in a thread created
 *       by the player (Audio Rendering Thread).
 */
class WHA_PUBLIC PlaybackDelegate {
public:
    virtual ~PlaybackDelegate() {}

    /**
     * Get playback rate supported by the device.
     * WHA will internally perform resampling into rate returned.
     * @return Playback rate in Hz, negative value on error.
     */
    virtual int getPlaybackRate() = 0;

    /**
     * Start audio playback.
     * @param format Audio format.
     * @param channels Channel count.
     * @return 0 if OK, non-zero value if failed.
     */
    virtual int start(AudioFormat format, int channels) = 0;

    /**
     * Stop audio playback.
     * @param behavior If STOP_DRAIN, drain (play all) buffered samples.
     *                 If STOP_DROP, drop buffered samples.
     */
    virtual void stop(StopBehavior behavior) = 0;

    /**
     * Play audio data at specified local time.
     * @param pts Local time when data has to be played, in nanoseconds.
     * @param buffer Audio data to play.
     * @param frames [in] Size of data to play in frames.
     *               Can be zero if WHA does not have data to play,
     *               pts should be ignored in that case.
     *               [out] Size of data consumed.
     * @param inSync [out] Is playback in sync or not.
     * @return Return 0 if OK, non-zero value on error.
     *
     */
    virtual int write(int64_t pts, const void* buffer, size_t* frames) = 0;
};

/**
 * FocusState that describes audio output expectations from the AVS system
 * that the WHA is in AudioFocus based playback.
 * Refer to {@link PlaybackDelegate#requestFocus()} for more detail.
 */
enum FocusState {
    /**
    * WHA is in the foreground and plays at regular volume
    */
    FOREGROUND,
    /**
    * WHA is in the background, and plays attenuated
    */
    BACKGROUND,
    /**
     * WHA should not be outputting any music
     */
    NO_FOCUS
};

/**
 * FocusChangeReason describes the reason the focus loss or gain was done.
 * This is passed into the FocusCallback.
 */
enum FocusChangeReason {
    /**
     * Device specific focus changes, such as losing internet connectivity, buffer underrun, etc.
     */
    NORMAL,
    /**
     * When a focus change event is explicitly due to AVS_COMMS feature,
     * which requires a separate UX handling from the WHA SDK.
     */
    AVS_COMMS
};

/**
 * This callback is called when the vendor is changing the WHA focus state
 * to the passed in FocusState. This callback is thread safe and blocking.
 * When the call returns, the WHA SDK will have made some change to
 * ensure that the new state has taken effect or will take effect soon.
 * The FocusCallback should only be called if {@link FocusState#FOREGROUND} or
 * {@link FocusState#BACKGROUND} was returned from the requestFocus call.
 * Once NO_FOCUS is passed to the callback, the callback will not be triggered
 * again. This callback will be valid until another requestFocus call has
 * returned or after a call to releaseFocus has returned.
 */
typedef void (*FocusCallback)(WHA* whaContext, FocusState state, FocusChangeReason changeReason);

class WHA_PUBLIC FocusDelegate {
public:
    virtual ~FocusDelegate() {}

    /**
     * requestFocus is called by the WHA SDK when it wishes to render audio
     * on the Content Channel.
     *
     * This call is a blocking call that returns a FocusState to indicate
     * whether or not focus has been granted in one form or another.
     *
     * The caller can call requestFocus, even if it already has focus.
     * If focus was previously granted, the old callback
     * is considered invalid and the new one should be used.
     *
     * If {@link FocusState#NO_FOCUS} is returned from this call, the WHA SDK will assume that
     * it will not be able to play until it learns otherwise by trying to acquire focus later.
     *
     * @param focusCallback the callback to be triggered. For more details,
     *        please refer to {@see FocusCallback}
     * @return the {@link FocusState} that is granted to the WHA library.
     */
    virtual FocusState requestFocus(FocusCallback focusCallback) = 0;

    /**
     * releaseFocus is called by the WHA SDK when it indicates it is surrendering the focus
     * (when it is finished with playback, as an example). This is a blocking call.
     *
     * @return true if focus was successfully released. False otherwise
     */
    virtual bool releaseFocus() = 0;
};

/**
 * Time delegate.
 *
 * This class is responsible for provide the access of local time.
 * WHA will use the time to maintain time sync and provide the playback
 * timestamp.  Note that this high resolution timer should be accurate
 * and stable.
 */
class WHA_PUBLIC TimeDelegate {
public:
    virtual ~TimeDelegate() {}

    /**
     * Get local time in nanoseconds.
     * @param localTime The current local time in nanoseconds.
     * @return 0 if OK.
     */
    virtual int getLocalTimeNs(int64_t* localTime) = 0;

    /**
     * Get nominal value of local clock drift.
     * Expected local clock drift = nominal +- tolerance.
     * In most cases nominal value should be 0.
     * The function is called when time synchronization starts.
     *
     * @return Nominal drift in ppm (parts per million) with
     *         at least 0.001 ppm precision.
     *         Positive value means our clock is slower,
     *         negative value means our clock is faster.
     */
    virtual double getNominalDriftPpm() = 0;

    /**
     * Get drift tolerance of local clock.
     * Expected local clock drift = nominal +- tolerance.
     * The function is called when time synchronization starts.
     *
     * @return Drift tolerance in ppm with
     *         at least 0.001 ppm precision.
     */
    virtual double getDriftTolerancePpm() = 0;

    /**
     * Get drift between clock used by getLocalTimeNs()
     * and audio subsystem clock. In most cases value returned
     * should be 0.0.
     * The function is called from Audio Rendering Thread
     * initializes resampler.
     *
     * @return Drift between local clock and audio clock in ppm
     *         with at least 0.001 ppm precision.
     *         Positive value means audio clock is slower,
     *         negative value means our clock is faster.
     */
    virtual double getAudioDriftPpm() = 0;

    /**
     * Get extra time to add at the beginning of playback.
     * This is a delay w.r.t. Echo Dot Gen 2 line out,
     * measured in nanoseconds.
     * The value returned may not necessary be always the same,
     * e.g. in case of line out vs speaker out.
     * This function is called at the beginning of song,
     * so if delay changes during playback because of
     * plugging/unplugging line out, audio may play out of sync
     * until the end of the song.
     *
     * @param offset Extra time to add at the beginning
     *               of playback in nanoseconds.
     *               Positive value will shift playback further
     *               into the future, negative value will
     *               move playback into the past.
     * @return 0 if OK.
     *         Any other value means failure, we will
     *         cancel the playback.
     */
     virtual int getPlayOffsetNs(int64_t* offset) = 0;
};

/**
 * Log Level
 * @see LoggingDelegate::log()
 */
enum LogLevel {
    LOG_VERBOSE = 1,
    LOG_DEBUG,
    LOG_INFO,
    LOG_WARN,
    LOG_ERROR,
    LOG_FATAL
};

/// Logging Delegate
class WHA_PUBLIC LoggingDelegate {
public:
    LoggingDelegate() {}
    virtual ~LoggingDelegate() {}

    /**
     * Log the message.
     * @param level Log level.
     * @param tag Component tag.
     * @param text Message to log.
     */
    virtual void log(LogLevel level, const char* tag, const char* text) = 0;
};
} // namespace wha

#endif // AMAZON_WHA_DELEGATES
